[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a senior researcher at Nokia Technologies working on deep neural network compression and explainable AI. Prior to that I was a postdoctoral researcher in the Multi-Source Probabilistic Inference group at University of Helsinki working with Professor Arto Klami.\nI completed my PhD in the Probabilistic Machine Leanring group under supervision of Professor Samuel Kaski in 2019. My thesis research lied in the space of human-in-the-loop machine learning with focus on knowledge elicitation, probabilistic modeling, and active learning. You can download my thesis here. After finishing my PhD and before starting the postdoctoral position, I had the opportunity to work with some amazing people at Sony AI in Tokyo, as a visiting researcher.\nMy main research interests include:\n Neural network compression: reducing the size of deep neural network models while maitaining their predictive performance as much as possible to ease their usage in decentralized environment. Machine learning Interpretability: making machine learning models understandable for human decision makers. Human-in-the-loop machine learning: combining human and machine intelligence to create more powerful models.  ","date":1671148800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1671148800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://homayunafra.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a senior researcher at Nokia Technologies working on deep neural network compression and explainable AI. Prior to that I was a postdoctoral researcher in the Multi-Source Probabilistic Inference group at University of Helsinki working with Professor Arto Klami.\nI completed my PhD in the Probabilistic Machine Leanring group under supervision of Professor Samuel Kaski in 2019. My thesis research lied in the space of human-in-the-loop machine learning with focus on knowledge elicitation, probabilistic modeling, and active learning.","tags":null,"title":"Homayun Afrabandpey","type":"authors"},{"authors":["Homayun Afrabandpey","Goutham Rangu","Honglei Zhang","Francesco Cricri","Emre Aksu","Hamed Rezazadegan Tavakoli"],"categories":null,"content":"","date":1671148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671148800,"objectID":"b599a4b05115f91f1100779b7fd3d6b4","permalink":"https://homayunafra.github.io/publication/conference-paper/2022-vcip/","publishdate":"2022-12-16T00:00:00Z","relpermalink":"/publication/conference-paper/2022-vcip/","section":"publication","summary":"This paper studies the effect of exploiting temporal dependency of successive weight updates on compressing communications in Federated Learning (FL). For this, we propose residual coding for FL, which utilizes temporal dependencies by communicating compressed residuals of the weight updates whenever they are beneficial to bandwidth. We further consider Temporal Context Adaptation (TCA) which compares co-located elements of consecutive weight updates to select optimal setting for compression of bitstream in DeepCABAC encoder. Following experimental settings of MPEG standard on Neural Network Compression (NNC), we demonstrate that both temporal dependency based technologies reduce communication overhead, where the maximum reduction is obtained using both technologies, simultaneously.","tags":["Source Themes"],"title":"On the importance of temporal dependencies of weight updates in communication efficient federated learning","type":"publication"},{"authors":["Homayun Afrabandpey","Michael Spranger"],"categories":null,"content":"","date":1667433600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667433600,"objectID":"3192064c076471937b4c559085d54ef6","permalink":"https://homayunafra.github.io/publication/conference-paper/2022-hill/","publishdate":"2022-11-03T00:00:00Z","relpermalink":"/publication/conference-paper/2022-hill/","section":"publication","summary":"We present a human-in-the-loop approach to generate counterfactual (CF) explanations that preserve global and local feasibility constraints. Global feasibility constraints refer to the causal constraints that are necessary for generating actionable CF explanation. Assuming a domain expert with knowledge on unary and binary causal constraints, our approach efficiently employs this knowledge to generate CF explanation by rejecting gradient steps that violate these constraints. Local feasibility constraints encode end-user's constraints for generating desirable CF explanation. We extract these constraints from the end-user of the model and exploit them during CF generation via user-defined distance metric. Through user studies, we demonstrate that incorporating causal constraints during CF generation results in significantly better explanations in terms of feasibility and desirability for participants. Adopting local and global feasibility constraints simultaneously, although improves user satisfaction, does not significantly improve desirability of the participants compared to only incorporating global constraints.","tags":["Source Themes"],"title":"Feasible and Desirable Counterfactual Generation by Preserving Human Defined Constraints","type":"publication"},{"authors":["Rangu Goutham","Homayun Afrabandpey","Francesco Cricri","Honglei Zhang","Emre Aksu","Miska Hannuksela","Hamed Rezazadegan Tavakoli"],"categories":null,"content":"","date":1666915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666915200,"objectID":"f625b6ac35e399f12e5a05faa82da7c3","permalink":"https://homayunafra.github.io/publication/conference-paper/2022-icip/","publishdate":"2022-10-28T00:00:00Z","relpermalink":"/publication/conference-paper/2022-icip/","section":"publication","summary":"A stochastic binary-ternary (SBT) quantization approach is introduced for communication efficient federated computation; form of collaborative computing where locally trained models are exchanged between institutes. Communication of deep neural network models could be highly inefficient due to their large size. This motivates model compression in which quantization is an important step. Two well-known quantization algorithms are binary and ternary quantization. The first leads into good compression, sacrificing accuracy. The second provides good accuracy with less compression. To better benefit from trade-off between accuracy and compression, we propose an algorithm to stochastically switch between binary and ternary quantization. By combining with uniform quantization, we further extend the proposed algorithm to a hierarchical method which results in even better compression without sacrificing the accuracy. We tested the proposed algorithm using Neural network Compression Test Model (NCTM) provided by MPEG community. Our results demonstrate that the hierarchical variant of the proposed algorithm outperforms other quantization algorithms in term of compression, while maintaining the accuracy competitive to that provided by other methods.","tags":["Source Themes"],"title":"Stochastic Binary-Ternary Quantization for Communication Efficient Federated Computation","type":"publication"},{"authors":["Homayun Afrabandpey","Anton Muravev","Hamed Rezazadegan Tavakoli","Honglei Zhang","Francesco Cricri","Moncef Gabbouj","Emre Aksu"],"categories":null,"content":"","date":1638057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638057600,"objectID":"7cbf93cedf5c2e7a99005b0004b59b00","permalink":"https://homayunafra.github.io/publication/conference-paper/2021-icip/","publishdate":"2021-11-28T00:00:00Z","relpermalink":"/publication/conference-paper/2021-icip/","section":"publication","summary":"Deep neural networks have huge number of parameters and require large number of bits for representation. This hinders their adoption in decentralized environments where model transfer among different parties is a characteristic of the environment while the communication bandwidth is limited. Parameter quantization is a compression approach to address this challenge by reducing the number of bits required to represent a model, e.g. a neural network. However, majority of existing neural network quantization methods do not exploit structural information of layers and parameters during quantization. In this paper, focusing on Convolutional Neural Networks (CNNs), we present a novel quantization approach by employing the structural information of neural network layers and their corresponding parameters. Starting from a pre-trained CNN, we categorize network parameters into different groups based on the similarity of their layers and their spatial structure. Parameters of each group are independently clustered and the centroid of each cluster is used as representative for all parameters in the cluster. Finally, the centroids and the cluster indexes of the parameters are used as a compact representation of the parameters. Experiments with two different tasks, i.e., acoustic scene classification and image compression, demonstrate the effectiveness of the proposed approach.","tags":["Source Themes"],"title":"Mind the structure: adopting structural information for deep neural network compression","type":"publication"},{"authors":["Ville Tanskanen","Chang Rajani","Homayun Afrabandpey","Aini Putkonen","Aur√©lien Nioche","Arto Klami"],"categories":null,"content":"","date":1638057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638057600,"objectID":"3b9976e6e12d879ba254aa9ffe16e8f6","permalink":"https://homayunafra.github.io/publication/conference-paper/2021-acml/","publishdate":"2021-11-28T00:00:00Z","relpermalink":"/publication/conference-paper/2021-acml/","section":"publication","summary":"In this work, we propose an interpretability utility, which explicates the trade-off between explanation fidelity and interpretability in the Bayesian framework.","tags":["Source Themes"],"title":"Modeling risky choices in unknown environments","type":"publication"},{"authors":["Homayun Afrabandpey","Tomi Peltola","Juho Piironen","Aki Vehtari","Samuel Kaski"],"categories":null,"content":"","date":1599177600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599177600,"objectID":"fe9fec6d3ca523e62f48c34f1b6068a4","permalink":"https://homayunafra.github.io/publication/journal-article/2020-bayesian_interpretability/","publishdate":"2020-09-04T00:00:00Z","relpermalink":"/publication/journal-article/2020-bayesian_interpretability/","section":"publication","summary":"In this work, we propose an interpretability utility, which explicates the trade-off between explanation fidelity and interpretability in the Bayesian framework.","tags":["Source Themes"],"title":"A decision-theoretic approach for model interpretability in Bayesian framework","type":"publication"},{"authors":["Homayun Afrabandpey","Tomi Peltola","Samuel Kaski"],"categories":null,"content":"","date":1569110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569110400,"objectID":"c7bf35fa598a923fdb970f6bca994d66","permalink":"https://homayunafra.github.io/publication/conference-paper/2019-ijcai/","publishdate":"2020-09-22T00:00:00Z","relpermalink":"/publication/conference-paper/2019-ijcai/","section":"publication","summary":"Learning predictive models from small high-dimensional data sets is a key problem in high-dimensional statistics. Expert knowledge elicitation can help, and a strong line of work focuses on directly eliciting informative prior distributions for parameters. This either requires considerable statistical expertise or is laborious, as the emphasis has been on accuracy and not on efficiency of the process. Another line of work queries about importance of features one at a time, assuming them to be independent and hence missing covariance information. In contrast, we propose eliciting expert knowledge about pairwise feature similarities, to borrow statistical strength in the predictions, and using sequential decision making techniques to minimize the effort of the expert.","tags":["Source Themes"],"title":"Human-in-the-loop active covariance learning for improving prediction in small data sets","type":"publication"},{"authors":["Javad Salimi Sartakhti","Homayun Afrabandpey","Nasser Ghadiri"],"categories":null,"content":"","date":1562716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562716800,"objectID":"81425bf54f26f00aaeec680a3d6b7d86","permalink":"https://homayunafra.github.io/publication/journal-article/2019-flstsvm/","publishdate":"2019-07-10T00:00:00Z","relpermalink":"/publication/journal-article/2019-flstsvm/","section":"publication","summary":"Least Squares Twin Support Vector Machine (LST-SVM) has been shown to be an efficient and fast algorithm for binary classification. In many real-world applications, samples may not deterministically be assigned to a single class; they come naturally with their associated uncertainties. Also, samples may not be equally importantand their importance degrees affect the classification. Despite its efficiency, LST-SVM still lacks the ability to deal with these situations. In this paper, we propose Fuzzy LST-SVM (FLST-SVM) to cope with these difficulties.","tags":["Source Themes"],"title":"Fuzzy least squares twin support vector machines","type":"publication"},{"authors":["Iiris Sundin","Tomi Peltola","Luana Micallef","Homayun Afrabandpey","Marta Soare","Muntasir Mamun Majumder","Pedram Daee","Chen He","Baris Serim","Aki Havulinna","Caroline Heckman","Giulio Jacucci","Pekka Martinen","Samuel Kaski"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"062e4996b9c664db3d3ffb9d5a511620","permalink":"https://homayunafra.github.io/publication/journal-article/2018-bioinformatics/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/publication/journal-article/2018-bioinformatics/","section":"publication","summary":"Precision medicine requires the ability to predict the efficacies of different treatments for a given individual using high-dimensional genomic measurements. However, identifying predictive features remains a challenge when the sample size is small. Incorporating expert knowledge offers a promising approach to improve predictions, but collecting such knowledge is laborious if the number of candidate features is very large. We introduce a probabilistic framework to incorporate expert feedback about the impact of genomic measurements on the outcome of interest and present a novel approach to collect the feedback efficiently, based on Bayesian experimental design.","tags":["Source Themes"],"title":"Improving genomics-based predictions for precision medicine through active elicitation of expert knowledge","type":"publication"},{"authors":["Mehran Safayani","Seyed Hashem Ahmadi","Homayun Afrabandpey","Abdolreza Mirzaei"],"categories":null,"content":"","date":1526342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526342400,"objectID":"266eb04e32fabe1de79f6fa211b80f9c","permalink":"https://homayunafra.github.io/publication/journal-article/2018-p2dcca/","publishdate":"2018-05-15T00:00:00Z","relpermalink":"/publication/journal-article/2018-p2dcca/","section":"publication","summary":"Two-dimensional canonical correlation analysis (2DCCA) has been successfully applied for image feature extraction. The method instead of concatenating the columns of the images to the one-dimensional vectors, directly works with two-dimensional image matrices. Although 2DCCA works well in different recognition tasks, it lacks a probabilistic interpretation. In this paper, we present a probabilistic framework for 2DCCA called probabilistic 2DCCA (P2DCCA) and an iterative EM based algorithm for optimizing the parameters.","tags":["Source Themes"],"title":"An EM based probabilistic two-dimensional CCA with application to face recognition","type":"publication"},{"authors":["Homayun Afrabandpey","Tomi Peltola","Samuel Kaski"],"categories":null,"content":"","date":1500076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500076800,"objectID":"69d35d67e94a54851907001c65275002","permalink":"https://homayunafra.github.io/publication/conference-paper/2017-umap/","publishdate":"2017-07-15T00:00:00Z","relpermalink":"/publication/conference-paper/2017-umap/","section":"publication","summary":"Regression under the \"small n$, large p\" condition, of small sample size n and large number of features p in the learning data set, is a recurring setting in which learning from data is difficult. With prior knowledge about relationships of the features, p can effectively be reduced, but explicating such prior knowledge is difficult for experts. In this paper we introduce a new method for eliciting expert prior knowledge about the similarity of the roles of features in the prediction task. The key idea is to use an interactive multidimensional-scaling (MDS) type scatterplot display of the features to elicit the similarity relationships, and then use the elicited relationships in the prior distribution of prediction parameters.","tags":["Source Themes"],"title":"Interactive prior elicitation of feature similarities for small sample size prediction","type":"publication"},{"authors":["Javad Salimi Sartakhti","Homayun Afrabandpey","Mohamad Saraee"],"categories":null,"content":"","date":1495152000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495152000,"objectID":"580f6a56d831a2e8ca2298f04287b653","permalink":"https://homayunafra.github.io/publication/journal-article/2017-salstsvm/","publishdate":"2017-05-19T00:00:00Z","relpermalink":"/publication/journal-article/2017-salstsvm/","section":"publication","summary":"Least squares twin support vector machine (LSTSVM) is a relatively new version of support vector machine (SVM) based on non-parallel twin hyperplanes. Although, LSTSVM is an extremely efficient and fast algorithm for binary classification, its parameters depend on the nature of the problem. Problem dependent parameters make the process of tuning the algorithm with best values for parameters very difficult, which affects the accuracy of the algorithm. The goal of this paper is to improve the accuracy of the LSTSVM algorithm by hybridizing it with simulated annealing.","tags":["Source Themes"],"title":"Simulated annealing least squares twin support vector machine (SA-LSTSVM) for pattern classification","type":"publication"},{"authors":["Seppo Virtanen","Homayun Afrabandpey","Samuel Kaski"],"categories":null,"content":"","date":1463616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463616000,"objectID":"f94dd5582af3c00efb7e2bff2f52de8c","permalink":"https://homayunafra.github.io/publication/conference-paper/2016-icassp/","publishdate":"2016-05-19T00:00:00Z","relpermalink":"/publication/conference-paper/2016-icassp/","section":"publication","summary":"A main goal of data visualization is to find, from among all the available alternatives, mappings to the 2D/3D display which are relevant to the user. Assuming user interaction data, or other auxiliary data about the items or their relationships, the goal is to identify which aspects in the primary data support the user's input and, equally importantly, which aspects of the user's potentially noisy input have support in the primary data. For solving the problem, we introduce a multi-view embedding in which a latent factorization identifies which aspects in the two data views (primary data and user data) are related and which are specific to only one of them.","tags":["Source Themes"],"title":"Visualizations relevant to the user by multi-view latent variable factorization","type":"publication"},{"authors":["Homayun Afrabandpey","Meysam Ghaffari","Abdolreza mirzaei","Mehran Safayani"],"categories":null,"content":"","date":1398038400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398038400,"objectID":"4f09d94301c0a5f1962f7a65fe371546","permalink":"https://homayunafra.github.io/publication/conference-paper/2014-icis/","publishdate":"2014-04-21T00:00:00Z","relpermalink":"/publication/conference-paper/2014-icis/","section":"publication","summary":"Bat Algorithm (BA) is a new meta-heuristic optimization algorithm, which has been developed rapidly and has been applied in different optimization tasks in recent years. In this paper an improved version of Bat algorithm with chaos is represented. The approach is based on the substitution of the random number generator (RNG) with chaotic sequences for parameter initialization.","tags":["Source Themes"],"title":"A novel bat algorithm based on chaos for optimization tasks","type":"publication"}]